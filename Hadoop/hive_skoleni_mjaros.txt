Klienti:
========

hive
  nebo
beeline -u jdbc:hive2://localhost:10000/default -n mjaros
  nebo v beeline:
!connect jdbc:hive2://<host>:<port> <user> <PASS>

pro hive2 port 10000
pro hive 2 interactive port 10500


Upravit CSV, aby obsahovalo 2 sloupce: Country, Minerals
=========================================================

# spec. prikaz pro csv (jinak vlastni script v pythonu, apod.)
csv 1 3 7 </home/_data/deposits/deposit.csv | tail -n +2 >deposit2.csv

# ale mame duplicity ...
diff -ay deposit.csv deposit2.csv | less

# zkusime bez 1. sloupce a pak znovu indexujeme
csv 3 7 </home/_data/deposits/deposit.csv | tail -n +2 | sort -u | awk '{printf("%d,%s\n", NR, $0)}' >deposit3.csv
diff -ay deposit.csv deposit3.csv | less


Preneseme na HDFS
=================

# ulozime na HDFS jako deposit.csv
hdfs dfs -mkdir /user/mjaros/db-deposit
hdfs dfs -put deposit3.csv /user/mjaros/deposit.csv
wc -l deposit3.csv


Vytvorime externi tabulku
=========================

CREATE EXTERNAL TABLE IF NOT EXISTS deposit (id BIGINT, country VARCHAR(255), minerals STRING)
ROW FORMAT
DELIMITED FIELDS TERMINATED BY ','
LINES TERMINATED BY '\n'
STORED AS TEXTFILE
LOCATION '/user/mjaros/db-deposit';

LOAD DATA INPATH '/user/mjaros/deposit.csv' INTO TABLE deposit;

hdfs dfs -ls /user/mjaros
hdfs dfs -ls /user/mjaros/db-deposit

# pozor 3 je nejaka divna ... neumi CSV!
SELECT * FROM deposit LIMIT 10;

# pri dropnuti externi tabulky zustava soubor nezmenen
DROP TABLE deposit;
hdfs dfs -ls /user/mjaros/db-deposit
hdfs dfs -mv /user/mjaros/db-deposit/deposit.csv /user/mjaros

# ted to snad bude ok, ale musime pouzit CSV serializator
# ale pozor, CSV pouze do textovych poli
# managed tabulka:

CREATE TABLE deposit_int (id BIGINT, country VARCHAR(255), minerals STRING)
ROW FORMAT SERDE 'org.apache.hadoop.hive.serde2.OpenCSVSerde'
WITH SERDEPROPERTIES (
   'separatorChar' = ',',
   'quoteChar'     = '"',
   'escapeChar'    = '\\'
)  
STORED AS TEXTFILE;

LOAD DATA INPATH '/user/mjaros/deposit.csv' INTO TABLE deposit;

hdfs dfs -find / -name deposit.csv

# overime tabulku, vsechna pole jsou STRING !
DESCRIBE FORMATTED deposit_int;

# codec snappy musi byt upercase, jinak hodi chybu ...
CREATE TABLE IF NOT EXISTS deposit_orc (id BIGINT, minerals VARCHAR(500))
PARTITIONED BY (country VARCHAR(255))
STORED AS ORC tblproperties ("orc.compress"="SNAPPY");

# pokud mame pouzity partitioning, musi se uvest tento partition
# select musi byt ve stejnem poradi jako definice tabulky do ktere se importuji data

INSERT OVERWRITE TABLE deposit_orc
PARTITION (country)
SELECT id, minerals, country
FROM deposit_int;

SHOW PARTITIONS deposit_orc;

SELECT country,count(*) FROM deposit_orc GROUP BY country;

# ulozime vystup tohoto selectu jako jinou tabulku
CREATE TABLE deposit_sel1
AS SELECT country, count(*)
FROM deposit_orc GROUP BY country;

SELECT * FROM deposit_sel1 LIMIT 10;

# pozor pri prejmenovani automaticky vytvorenych sloupcu, je treba je uzavrit do zpetnych lomitek ``
ALTER TABLE deposit_sel1 CHANGE COLUMN `_c1` num INT;

SELECT * FROM deposit_sel1 LIMIT 10;
SELECT * FROM deposit_sel1 ORDER BY num DESC, country ASC;












select * 
from (
select stat stat, mesic, prumer, rank() over (partition by mesic order by prumer desc) poradi
from (select stat, mesic, avg(teplota) prumer 
from pocasi 
group by stat, mesic) poc_prum
) poc_prum_rank
where poradi=1;


select stat, stanice, min(tepl_diff) max_diff
from (
select stat, stanice, 
teplota - lag(teplota,1,null) over (partition by stanice order by stanice, mesic, den, hodina) tepl_diff
from pocasi) pocasi_diff
group by stat, stanice;



